#!/usr/bin/env python3
"""
HLXL Brain - Phase 3 Corpus Generator
Generate long-form reasoning examples with extended sequences.

Phase 3 Focus:
- Extended sequences (256-512 tokens vs current 128)
- Context maintenance across operations
- Variable binding and stateful operations
- Conditional logic chains
- Recursive patterns
- Complex multi-step programs

Target: 400+ examples
"""

from typing import List, Tuple
import random


class Phase3CorpusGenerator:
    """Generate Phase 3: Long-form Reasoning corpus."""

    def __init__(self):
        self.examples: List[Tuple[str, str]] = []

    def generate_long_programs(self) -> List[Tuple[str, str]]:
        """Generate long multi-step programs (10-20 operations)."""
        examples = []

        # Data processing pipelines
        pipelines = [
            ("Build a data processing pipeline that loads multiple files, merges them, cleans nulls, validates schema, transforms columns, aggregates by group, and exports to three formats",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸpipelineðŸœ2 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "load_many"ðŸœ1 ["data1.csv", "data2.csv", "data3.csv"]ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "merge"ðŸœ1 âŸonðŸœ2 "id"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 ðŸœŠ1000ðŸœ0 "not_null"ðŸœ1 âŸvalueðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "validate"ðŸœ1 âŸschemaðŸœ2 "data.schema.json"ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "transform"ðŸœ1 âŸnormalizeðŸœ2 ["col1", "col2"]ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "group_by"ðŸœ1 "category"ðŸœ2 ðŸœŠ1000ðŸœ0 "sum"ðŸœ1 âŸrevenueðŸœ‚ðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "export"ðŸœ1 ["results.csv", "results.json", "results.parquet"]ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Create an ETL pipeline that extracts from API, transforms JSON, validates fields, enriches with lookups, filters invalid records, deduplicates, sorts, and loads to database",
             'ðŸœŠ1000ðŸœ0 "pipeline"ðŸœ1 ðŸœŠ1000ðŸœ0 "extract"ðŸœ1 âŸapiðŸœ2 "https://api.example.com/data"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "parse"ðŸœ1 "json"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "validate"ðŸœ1 ["id", "name", "email"]ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "enrich"ðŸœ1 âŸlookupðŸœ2 "users.db"ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_valid"ðŸœ‚ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "deduplicate"ðŸœ1 âŸbyðŸœ2 "id"ðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "sort"ðŸœ1 âŸbyðŸœ2 "timestamp"ðŸœ‚ðŸœ8 ðŸœŠ1000ðŸœ0 "load"ðŸœ1 âŸdatabaseðŸœ2 "warehouse.db"ðŸœ‚ðŸœ‚'),

            ("Build a file processing workflow that scans directory, filters by pattern, reads each file, extracts metadata, validates format, compresses, backs up to remote, and logs results",
             'ðŸœŠ1000ðŸœ0 "workflow"ðŸœ1 ðŸœŠ1000ðŸœ0 "scan"ðŸœ1 "/data/input"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 "*.log"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "map"ðŸœ1 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "read"ðŸœ1 âŸfileðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "extract_metadata"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "validate_format"ðŸœ1 "log"ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "compress"ðŸœ1 "gzip"ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "backup"ðŸœ1 âŸremoteðŸœ2 "s3://backups"ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "log_results"ðŸœ1 "process.log"ðŸœ‚ðŸœ‚'),

            ("Create a web scraping pipeline that fetches URLs, parses HTML, extracts links, follows pagination, filters duplicates, downloads images, resizes, and stores metadata",
             'ðŸœŠ1000ðŸœ0 "scraper"ðŸœ1 ðŸœŠ1000ðŸœ0 "fetch"ðŸœ1 "https://example.com/start"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "parse"ðŸœ1 "html"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "extract"ðŸœ1 âŸlinksðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "paginate"ðŸœ1 âŸmax_pagesðŸœ2 10ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "deduplicate"ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "download"ðŸœ1 âŸimagesðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "resize"ðŸœ1 800ðŸœ2 600ðŸœ‚ðŸœ8 ðŸœŠ1000ðŸœ0 "store"ðŸœ1 âŸmetadataðŸœ2 "scrape.db"ðŸœ‚ðŸœ‚'),

            ("Build a machine learning pipeline that loads dataset, splits train/test, normalizes features, trains model, validates accuracy, tunes hyperparameters, evaluates, and exports model",
             'ðŸœŠ1000ðŸœ0 "ml_pipeline"ðŸœ1 ðŸœŠ1000ðŸœ0 "load"ðŸœ1 "dataset.csv"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "split"ðŸœ1 âŸtrainðŸœ2 0.8ðŸœ3 âŸtestðŸœ4 0.2ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "normalize"ðŸœ1 âŸfeaturesðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "train"ðŸœ1 âŸmodelðŸœ2 "random_forest"ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "validate"ðŸœ1 âŸmetricðŸœ2 "accuracy"ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "tune"ðŸœ1 âŸhyperparametersðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "evaluate"ðŸœ1 âŸtest_setðŸœ‚ðŸœ8 ðŸœŠ1000ðŸœ0 "export"ðŸœ1 "model.pkl"ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(pipelines)

        # Complex transformations
        transforms = [
            ("Transform nested JSON by flattening structure, renaming keys, converting types, filtering nulls, grouping by category, computing aggregates, and reshaping to wide format",
             'ðŸœŠ1000ðŸœ0 "transform"ðŸœ1 ðŸœŠ1000ðŸœ0 "flatten"ðŸœ1 âŸjsonðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "rename"ðŸœ1 {"old_key": "new_key"}ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "convert"ðŸœ1 âŸtypesðŸœ2 {"age": "int", "score": "float"}ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 ðŸœŠ1000ðŸœ0 "not_null"ðŸœ‚ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "group_by"ðŸœ1 "category"ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "aggregate"ðŸœ1 {"sum": âŸrevenue, "mean": âŸscore}ðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "pivot"ðŸœ1 âŸwideðŸœ‚ðŸœ‚'),

            ("Process time series data by resampling to hourly, interpolating missing values, computing rolling averages, detecting anomalies, smoothing outliers, and forecasting next values",
             'ðŸœŠ1000ðŸœ0 "timeseries"ðŸœ1 ðŸœŠ1000ðŸœ0 "resample"ðŸœ1 "1H"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "interpolate"ðŸœ1 âŸmethodðŸœ2 "linear"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "rolling"ðŸœ1 âŸwindowðŸœ2 24ðŸœ3 âŸfnðŸœ4 "mean"ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "detect_anomalies"ðŸœ1 âŸthresholdðŸœ2 3.0ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "smooth"ðŸœ1 âŸoutliersðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "forecast"ðŸœ1 âŸstepsðŸœ2 48ðŸœ‚ðŸœ‚'),

            ("Analyze text corpus by tokenizing documents, removing stopwords, computing TF-IDF, clustering similar docs, extracting topics, ranking by relevance, and generating summary",
             'ðŸœŠ1000ðŸœ0 "text_analysis"ðŸœ1 ðŸœŠ1000ðŸœ0 "tokenize"ðŸœ1 âŸdocumentsðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "remove_stopwords"ðŸœ1 âŸlanguageðŸœ2 "en"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "tfidf"ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "cluster"ðŸœ1 âŸkðŸœ2 5ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "extract_topics"ðŸœ1 âŸmethodðŸœ2 "lda"ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "rank"ðŸœ1 âŸbyðŸœ2 "relevance"ðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "summarize"ðŸœ1 âŸmax_lengthðŸœ2 200ðŸœ‚ðŸœ‚'),

            ("Process image batch by loading from directory, converting color space, applying filters, detecting edges, segmenting regions, extracting features, classifying content, and saving results",
             'ðŸœŠ1000ðŸœ0 "image_batch"ðŸœ1 ðŸœŠ1000ðŸœ0 "load"ðŸœ1 "/images/*.jpg"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "convert"ðŸœ1 âŸcolorspaceðŸœ2 "RGB"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 âŸgaussianðŸœ2 5ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "detect_edges"ðŸœ1 âŸmethodðŸœ2 "canny"ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "segment"ðŸœ1 âŸregionsðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "extract_features"ðŸœ‚ðŸœ7 ðŸœŠ1000ðŸœ0 "classify"ðŸœ1 âŸmodelðŸœ2 "resnet50"ðŸœ‚ðŸœ8 ðŸœŠ1000ðŸœ0 "save"ðŸœ1 "results/"ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(transforms)
        return examples

    def generate_stateful_operations(self) -> List[Tuple[str, str]]:
        """Generate stateful operations with counters and accumulators."""
        examples = []

        # Counter patterns
        counters = [
            ("Initialize counter at 0, increment for each valid item, decrement for each invalid, return final count",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸcountðŸœ2 0ðŸœ3 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸitemsðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_valid"ðŸœ1 âŸitemðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "increment"ðŸœ1 âŸcountðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "decrement"ðŸœ1 âŸcountðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 âŸcountðŸœ‚ðŸœ‚'),

            ("Create accumulator with initial value, fold over list adding elements, filter sum if exceeds threshold, else return sum",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸaccðŸœ2 0ðŸœ3 ðŸœŠ1000ðŸœ0 "fold"ðŸœ1 âŸlistðŸœ2 ðŸœŠ1000ðŸœ0 "add"ðŸœ1 âŸaccðŸœ2 âŸitemðŸœ‚ðŸœ3 âŸaccðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "gt"ðŸœ1 âŸaccðŸœ2 1000ðŸœ‚ðŸœ‚ðŸœ2 1000ðŸœ3 âŸaccðŸœ‚ðŸœ‚'),

            ("Maintain running statistics: count items, sum values, compute mean, track min and max, calculate variance",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸstatsðŸœ2 {"count": 0, "sum": 0, "min": âŸinf, "max": -âŸinf}ðŸœ3 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸvaluesðŸœ2 ðŸœŠ1000ðŸœ0 "update"ðŸœ1 âŸstatsðŸœ2 ðŸœŠ1000ðŸœ0 "record"ðŸœ1 {"count": +1, "sum": +âŸvalue, "min": ðŸœŠ1000ðŸœ0 "min"ðŸœ1 âŸminðŸœ2 âŸvalueðŸœ‚, "max": ðŸœŠ1000ðŸœ0 "max"ðŸœ1 âŸmaxðŸœ2 âŸvalueðŸœ‚}ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 âŸmeanðŸœ2 ðŸœŠ1000ðŸœ0 "div"ðŸœ1 âŸsumðŸœ2 âŸcountðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Track state machine with transitions: initialize state, process events, transition based on conditions, emit actions, return final state",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸstateðŸœ2 "idle"ðŸœ3 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸeventsðŸœ2 ðŸœŠ1000ðŸœ0 "match"ðŸœ1 âŸstateðŸœ2 {"idle": ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸeventðŸœ2 "start"ðŸœ‚ðŸœ‚ðŸœ2 "running"ðŸœ3 "idle"ðŸœ‚, "running": ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸeventðŸœ2 "stop"ðŸœ‚ðŸœ‚ðŸœ2 "idle"ðŸœ3 "running"ðŸœ‚}ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 âŸstateðŸœ‚ðŸœ‚'),

            ("Build histogram by initializing bins, iterating values, incrementing bin counts, normalizing by total, return distribution",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸbinsðŸœ2 [0, 0, 0, 0, 0]ðŸœ3 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸvaluesðŸœ2 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸbinðŸœ2 ðŸœŠ1000ðŸœ0 "floor"ðŸœ1 ðŸœŠ1000ðŸœ0 "div"ðŸœ1 âŸvalueðŸœ2 10ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "increment"ðŸœ1 ðŸœŠ1000ðŸœ0 "at"ðŸœ1 âŸbinsðŸœ2 âŸbinðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "normalize"ðŸœ1 âŸbinsðŸœ2 ðŸœŠ1000ðŸœ0 "sum"ðŸœ1 âŸbinsðŸœ‚ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(counters)

        # Recursive patterns
        recursion = [
            ("Recursively traverse tree: visit node, process value, recurse on left child, recurse on right child, collect results",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸtraverseðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸnodeðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_null"ðŸœ1 âŸnodeðŸœ‚ðŸœ‚ðŸœ2 []ðŸœ3 ðŸœŠ1000ðŸœ0 "concat"ðŸœ1 ðŸœŠ1000ðŸœ0 "traverse"ðŸœ1 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸnodeðŸœ2 "left"ðŸœ‚ðŸœ‚ðŸœ2 [ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸnodeðŸœ2 "value"ðŸœ‚]ðŸœ3 ðŸœŠ1000ðŸœ0 "traverse"ðŸœ1 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸnodeðŸœ2 "right"ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Recursively compute factorial: base case if n equals 0 return 1, else return n times factorial of n minus 1",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸfactorialðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸnðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸnðŸœ2 0ðŸœ‚ðŸœ‚ðŸœ2 1ðŸœ3 ðŸœŠ1000ðŸœ0 "mul"ðŸœ1 âŸnðŸœ2 ðŸœŠ1000ðŸœ0 "factorial"ðŸœ1 ðŸœŠ1000ðŸœ0 "sub"ðŸœ1 âŸnðŸœ2 1ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Recursively flatten nested lists: if element is list, recursively flatten and concatenate, else wrap in list and return",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸflattenðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸlstðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_empty"ðŸœ1 âŸlstðŸœ‚ðŸœ‚ðŸœ2 []ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸheadðŸœ2 ðŸœŠ1000ðŸœ0 "first"ðŸœ1 âŸlstðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸtailðŸœ2 ðŸœŠ1000ðŸœ0 "rest"ðŸœ1 âŸlstðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "concat"ðŸœ1 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_list"ðŸœ1 âŸheadðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "flatten"ðŸœ1 âŸheadðŸœ‚ðŸœ3 [âŸhead]ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "flatten"ðŸœ1 âŸtailðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Recursively search directory tree: for each entry, if directory recurse into it, if file check pattern match, collect all matches",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸsearchðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸpathðŸœ2 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸentriesðŸœ2 ðŸœŠ1000ðŸœ0 "list"ðŸœ1 âŸpathðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "flat_map"ðŸœ1 âŸentriesðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸentryðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_dir"ðŸœ1 âŸentryðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "search"ðŸœ1 âŸentryðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "matches"ðŸœ1 âŸentryðŸœ2 âŸpatternðŸœ‚ðŸœ‚ðŸœ2 [âŸentry]ðŸœ3 []ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Recursively merge sorted lists: compare heads, take smaller, recurse on remainder, handle empty base cases",
             'ðŸœŠ1000ðŸœ0 "define"ðŸœ1 âŸmergeðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸaðŸœ2 âŸbðŸœ3 ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "is_empty"ðŸœ1 âŸaðŸœ‚, âŸb], [ðŸœŠ1000ðŸœ0 "is_empty"ðŸœ1 âŸbðŸœ‚, âŸa], [ðŸœŠ1000ðŸœ0 "lt"ðŸœ1 ðŸœŠ1000ðŸœ0 "first"ðŸœ1 âŸaðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "first"ðŸœ1 âŸbðŸœ‚ðŸœ‚ðŸœ‚, ðŸœŠ1000ðŸœ0 "cons"ðŸœ1 ðŸœŠ1000ðŸœ0 "first"ðŸœ1 âŸaðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "merge"ðŸœ1 ðŸœŠ1000ðŸœ0 "rest"ðŸœ1 âŸaðŸœ‚ðŸœ2 âŸbðŸœ‚ðŸœ‚], ["else", ðŸœŠ1000ðŸœ0 "cons"ðŸœ1 ðŸœŠ1000ðŸœ0 "first"ðŸœ1 âŸbðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "merge"ðŸœ1 âŸaðŸœ2 ðŸœŠ1000ðŸœ0 "rest"ðŸœ1 âŸbðŸœ‚ðŸœ‚ðŸœ‚]ðŸœ‚ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(recursion)
        return examples

    def generate_conditional_logic(self) -> List[Tuple[str, str]]:
        """Generate complex conditional logic chains."""
        examples = []

        conditions = [
            ("If user is admin then grant full access, elif user is moderator then grant edit access, elif user is member then grant read access, else deny",
             'ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸroleðŸœ2 "admin"ðŸœ‚, ðŸœŠ1000ðŸœ0 "grant"ðŸœ1 "full_access"ðŸœ‚], [ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸroleðŸœ2 "moderator"ðŸœ‚, ðŸœŠ1000ðŸœ0 "grant"ðŸœ1 "edit_access"ðŸœ‚], [ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸroleðŸœ2 "member"ðŸœ‚, ðŸœŠ1000ðŸœ0 "grant"ðŸœ1 "read_access"ðŸœ‚], ["else", ðŸœŠ1000ðŸœ0 "deny"ðŸœ‚]ðŸœ‚'),

            ("Validate input: if empty return error, elif too short return warning, elif contains invalid chars return error, else accept",
             'ðŸœŠ1000ðŸœ0 "validate"ðŸœ1 ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "is_empty"ðŸœ1 âŸinputðŸœ‚ðŸœ‚, {"status": "error", "msg": "Input required"}], [ðŸœŠ1000ðŸœ0 "lt"ðŸœ1 ðŸœŠ1000ðŸœ0 "len"ðŸœ1 âŸinputðŸœ‚ðŸœ2 3ðŸœ‚ðŸœ‚, {"status": "warning", "msg": "Too short"}], [ðŸœŠ1000ðŸœ0 "contains_invalid"ðŸœ1 âŸinputðŸœ‚ðŸœ‚, {"status": "error", "msg": "Invalid characters"}], ["else", {"status": "ok"}]ðŸœ‚ðŸœ‚'),

            ("Route request: if GET and path starts with api serve json, elif POST and authenticated process form, elif static file serve file, else 404",
             'ðŸœŠ1000ðŸœ0 "route"ðŸœ1 ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸmethodðŸœ2 "GET"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "starts_with"ðŸœ1 âŸpathðŸœ2 "/api"ðŸœ‚ðŸœ‚, ðŸœŠ1000ðŸœ0 "serve_json"ðŸœ1 âŸresponseðŸœ‚], [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "eq"ðŸœ1 âŸmethodðŸœ2 "POST"ðŸœ‚ðŸœ2 âŸauthenticatedðŸœ‚ðŸœ‚, ðŸœŠ1000ðŸœ0 "process_form"ðŸœ1 âŸdataðŸœ‚], [ðŸœŠ1000ðŸœ0 "is_static"ðŸœ1 âŸpathðŸœ‚ðŸœ‚, ðŸœŠ1000ðŸœ0 "serve_file"ðŸœ1 âŸpathðŸœ‚], ["else", ðŸœŠ1000ðŸœ0 "error"ðŸœ1 404ðŸœ‚]ðŸœ‚ðŸœ‚'),

            ("Process payment: if amount exceeds balance return insufficient funds, elif fraud detected return fraud alert, elif daily limit reached return limit exceeded, else process transaction",
             'ðŸœŠ1000ðŸœ0 "payment"ðŸœ1 ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "gt"ðŸœ1 âŸamountðŸœ2 âŸbalanceðŸœ‚ðŸœ‚, {"status": "error", "code": "insufficient_funds"}], [ðŸœŠ1000ðŸœ0 "detect_fraud"ðŸœ1 âŸtransactionðŸœ‚ðŸœ‚, {"status": "blocked", "code": "fraud_alert"}], [ðŸœŠ1000ðŸœ0 "ge"ðŸœ1 âŸdaily_totalðŸœ2 âŸdaily_limitðŸœ‚ðŸœ‚, {"status": "error", "code": "limit_exceeded"}], ["else", ðŸœŠ1000ðŸœ0 "process"ðŸœ1 âŸtransactionðŸœ‚]ðŸœ‚ðŸœ‚'),

            ("Classify data: if numeric and positive return category A, elif numeric and negative return category B, elif string and uppercase return category C, elif string and lowercase return category D, else unknown",
             'ðŸœŠ1000ðŸœ0 "classify"ðŸœ1 ðŸœŠ1000ðŸœ0 "cond"ðŸœ1 [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_numeric"ðŸœ1 âŸdataðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "gt"ðŸœ1 âŸdataðŸœ2 0ðŸœ‚ðŸœ‚, "category_A"], [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_numeric"ðŸœ1 âŸdataðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "lt"ðŸœ1 âŸdataðŸœ2 0ðŸœ‚ðŸœ‚, "category_B"], [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_string"ðŸœ1 âŸdataðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "is_uppercase"ðŸœ1 âŸdataðŸœ‚ðŸœ‚, "category_C"], [ðŸœŠ1000ðŸœ0 "and"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_string"ðŸœ1 âŸdataðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "is_lowercase"ðŸœ1 âŸdataðŸœ‚ðŸœ‚, "category_D"], ["else", "unknown"]ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(conditions)

        # Nested conditionals
        nested = [
            ("Process order: if inventory available then if customer verified then if payment successful then ship order else refund else reject else backorder",
             'ðŸœŠ1000ðŸœ0 "process_order"ðŸœ1 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "check_inventory"ðŸœ1 âŸproductðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "verify_customer"ðŸœ1 âŸcustomerðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "process_payment"ðŸœ1 âŸpaymentðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "ship"ðŸœ1 âŸorderðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "refund"ðŸœ1 âŸpaymentðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "reject"ðŸœ1 "unverified"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "backorder"ðŸœ1 âŸproductðŸœ‚ðŸœ‚'),

            ("Authenticate user: if username exists then if password matches then if MFA enabled then if token valid then grant access else deny else grant access else deny else register",
             'ðŸœŠ1000ðŸœ0 "authenticate"ðŸœ1 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "user_exists"ðŸœ1 âŸusernameðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "password_match"ðŸœ1 âŸpasswordðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "mfa_enabled"ðŸœ1 âŸuserðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "validate_token"ðŸœ1 âŸtokenðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "grant_access"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "deny"ðŸœ1 "invalid_token"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "grant_access"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "deny"ðŸœ1 "wrong_password"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "register"ðŸœ1 âŸusernameðŸœ‚ðŸœ‚'),

            ("Process file upload: if file size valid then if file type allowed then if virus scan passes then if metadata extracted then store file else reject else quarantine else reject else reject",
             'ðŸœŠ1000ðŸœ0 "upload"ðŸœ1 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "check_size"ðŸœ1 âŸfileðŸœ2 âŸmax_sizeðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "check_type"ðŸœ1 âŸfileðŸœ2 âŸallowed_typesðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "scan"ðŸœ1 âŸfileðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "if"ðŸœ1 ðŸœŠ1000ðŸœ0 "extract_metadata"ðŸœ1 âŸfileðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "store"ðŸœ1 âŸfileðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "reject"ðŸœ1 "metadata_error"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "quarantine"ðŸœ1 âŸfileðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "reject"ðŸœ1 "invalid_type"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "reject"ðŸœ1 "file_too_large"ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(nested)
        return examples

    def generate_iteration_patterns(self) -> List[Tuple[str, str]]:
        """Generate iteration patterns with loops and state."""
        examples = []

        loops = [
            ("For each item in list, if item passes filter apply transform and append to results, continue until list exhausted",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresultsðŸœ2 []ðŸœ3 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸlistðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸitemðŸœ2 ðŸœŠ1000ðŸœ0 "when"ðŸœ1 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 âŸitemðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "append"ðŸœ1 âŸresultsðŸœ2 ðŸœŠ1000ðŸœ0 "transform"ðŸœ1 âŸitemðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 âŸresultsðŸœ‚ðŸœ‚'),

            ("While condition true, fetch batch of items, process each item, update progress counter, check condition, repeat",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸprogressðŸœ2 0ðŸœ3 ðŸœŠ1000ðŸœ0 "while"ðŸœ1 ðŸœŠ1000ðŸœ0 "lt"ðŸœ1 âŸprogressðŸœ2 âŸtotalðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸbatchðŸœ2 ðŸœŠ1000ðŸœ0 "fetch"ðŸœ1 âŸprogressðŸœ2 âŸbatch_sizeðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸbatchðŸœ2 ðŸœŠ1000ðŸœ0 "process"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "update"ðŸœ1 âŸprogressðŸœ2 ðŸœŠ1000ðŸœ0 "add"ðŸœ1 âŸprogressðŸœ2 âŸbatch_sizeðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Iterate with early exit: for each element, check condition, if met return element and break, else continue to next, if exhausted return null",
             'ðŸœŠ1000ðŸœ0 "for_each"ðŸœ1 âŸelementsðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸelemðŸœ2 ðŸœŠ1000ðŸœ0 "when"ðŸœ1 ðŸœŠ1000ðŸœ0 "check"ðŸœ1 âŸelemðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 âŸelemðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 âŸnullðŸœ‚'),

            ("Nested loops: for each category, for each item in category, for each property of item, validate property, collect all validation results",
             'ðŸœŠ1000ðŸœ0 "flat_map"ðŸœ1 âŸcategoriesðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸcategoryðŸœ2 ðŸœŠ1000ðŸœ0 "flat_map"ðŸœ1 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸcategoryðŸœ2 "items"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸitemðŸœ2 ðŸœŠ1000ðŸœ0 "map"ðŸœ1 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸitemðŸœ2 "properties"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "validate"ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Parallel iteration: map over list with async function, collect promises, wait for all to complete, aggregate results",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸpromisesðŸœ2 ðŸœŠ1000ðŸœ0 "map"ðŸœ1 âŸlistðŸœ2 ðŸœŠ1000ðŸœ0 "async"ðŸœ1 ðŸœŠ1000ðŸœ0 "fetch"ðŸœ1 âŸitemðŸœ‚ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresultsðŸœ2 ðŸœŠ1000ðŸœ0 "await_all"ðŸœ1 âŸpromisesðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "aggregate"ðŸœ1 âŸresultsðŸœ‚ðŸœ‚'),
        ]

        examples.extend(loops)

        # Generator patterns
        generators = [
            ("Create lazy sequence generator: yield first element, compute next based on previous, continue infinitely or until condition",
             'ðŸœŠ1000ðŸœ0 "generator"ðŸœ1 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸcurrentðŸœ2 0ðŸœ3 ðŸœŠ1000ðŸœ0 "loop"ðŸœ1 ðŸœŠ1000ðŸœ0 "yield"ðŸœ1 âŸcurrentðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "update"ðŸœ1 âŸcurrentðŸœ2 ðŸœŠ1000ðŸœ0 "next"ðŸœ1 âŸcurrentðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Stream processing: take items from input stream, transform each item, filter results, yield to output stream, handle backpressure",
             'ðŸœŠ1000ðŸœ0 "stream"ðŸœ1 ðŸœŠ1000ðŸœ0 "from"ðŸœ1 âŸinputðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "map"ðŸœ1 ðŸœŠ1000ðŸœ0 "transform"ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "filter"ðŸœ1 ðŸœŠ1000ðŸœ0 "is_valid"ðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "to"ðŸœ1 âŸoutputðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "with_backpressure"ðŸœ1 1000ðŸœ‚ðŸœ‚'),

            ("Range iteration with step: start at begin, step by increment, check if less than end, yield value, continue",
             'ðŸœŠ1000ðŸœ0 "generator"ðŸœ1 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸiðŸœ2 âŸbeginðŸœ3 ðŸœŠ1000ðŸœ0 "while"ðŸœ1 ðŸœŠ1000ðŸœ0 "lt"ðŸœ1 âŸiðŸœ2 âŸendðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "yield"ðŸœ1 âŸiðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "update"ðŸœ1 âŸiðŸœ2 ðŸœŠ1000ðŸœ0 "add"ðŸœ1 âŸiðŸœ2 âŸstepðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),
        ]

        examples.extend(generators)
        return examples

    def generate_context_maintenance(self) -> List[Tuple[str, str]]:
        """Generate examples requiring context maintenance across operations."""
        examples = []

        context = [
            ("Define variables x, y, z at start, use x in operation 1, use y in operation 2, combine x and y in operation 3, use z in operation 4, return all results",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸxðŸœ2 10ðŸœ3 âŸyðŸœ4 20ðŸœ5 âŸzðŸœ6 30ðŸœ7 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresult1ðŸœ2 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 âŸxðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresult2ðŸœ2 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 âŸyðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresult3ðŸœ2 ðŸœŠ1000ðŸœ0 "combine"ðŸœ1 âŸxðŸœ2 âŸyðŸœ‚ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸresult4ðŸœ2 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 âŸzðŸœ‚ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "return"ðŸœ1 [âŸresult1, âŸresult2, âŸresult3, âŸresult4]ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Load configuration at beginning, extract database settings, connect to database, extract API settings, configure API client, use both throughout pipeline",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸconfigðŸœ2 ðŸœŠ1000ðŸœ0 "load"ðŸœ1 "config.json"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸdb_settingsðŸœ2 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸconfigðŸœ2 "database"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸdbðŸœ2 ðŸœŠ1000ðŸœ0 "connect"ðŸœ1 âŸdb_settingsðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸapi_settingsðŸœ2 ðŸœŠ1000ðŸœ0 "get"ðŸœ1 âŸconfigðŸœ2 "api"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸapiðŸœ2 ðŸœŠ1000ðŸœ0 "configure"ðŸœ1 âŸapi_settingsðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "pipeline"ðŸœ1 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "fetch_from_api"ðŸœ1 âŸapiðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "store_in_db"ðŸœ1 âŸdbðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Initialize session with user context, track user actions throughout workflow, update user state after each step, log all actions with user context, cleanup session at end",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸsessionðŸœ2 ðŸœŠ1000ðŸœ0 "init_session"ðŸœ1 âŸuserðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "try"ðŸœ1 ðŸœŠ1000ðŸœ0 "sequence"ðŸœ1 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸaction1ðŸœ2 ðŸœŠ1000ðŸœ0 "do_action"ðŸœ1 "step1"ðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "log"ðŸœ1 âŸsessionðŸœ2 âŸaction1ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "update_state"ðŸœ1 âŸsessionðŸœ2 âŸaction1ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸaction2ðŸœ2 ðŸœŠ1000ðŸœ0 "do_action"ðŸœ1 "step2"ðŸœ‚ðŸœ‚ðŸœ5 ðŸœŠ1000ðŸœ0 "log"ðŸœ1 âŸsessionðŸœ2 âŸaction2ðŸœ‚ðŸœ6 ðŸœŠ1000ðŸœ0 "update_state"ðŸœ1 âŸsessionðŸœ2 âŸaction2ðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "finally"ðŸœ1 ðŸœŠ1000ðŸœ0 "cleanup"ðŸœ1 âŸsessionðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚'),

            ("Build execution plan with dependencies: step A defines result, step B uses result from A, step C uses results from A and B, step D uses result from C",
             'ðŸœŠ1000ðŸœ0 "let"ðŸœ1 âŸplanðŸœ2 ðŸœŠ1000ðŸœ0 "plan"ðŸœ1 ðŸœŠ1000ðŸœ0 "step"ðŸœ1 "A"ðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 "value_A"ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 "step"ðŸœ1 "B"ðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸresult_AðŸœ2 ðŸœŠ1000ðŸœ0 "compute"ðŸœ1 âŸresult_AðŸœ‚ðŸœ‚ðŸœ3 ["A"]ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "step"ðŸœ1 "C"ðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸresult_AðŸœ2 âŸresult_BðŸœ3 ðŸœŠ1000ðŸœ0 "combine"ðŸœ1 âŸresult_AðŸœ2 âŸresult_BðŸœ‚ðŸœ‚ðŸœ3 ["A", "B"]ðŸœ‚ðŸœ4 ðŸœŠ1000ðŸœ0 "step"ðŸœ1 "D"ðŸœ2 ðŸœŠ1000ðŸœ0 "fn"ðŸœ1 âŸresult_CðŸœ2 ðŸœŠ1000ðŸœ0 "finalize"ðŸœ1 âŸresult_CðŸœ‚ðŸœ‚ðŸœ3 ["C"]ðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 "execute"ðŸœ1 âŸplanðŸœ‚ðŸœ‚'),
        ]

        examples.extend(context)
        return examples

    def generate_all(self) -> List[Tuple[str, str]]:
        """Generate all Phase 3 examples."""
        print("Generating Phase 3 corpus...")

        self.examples = []
        self.examples.extend(self.generate_long_programs())
        print(f"  âœ“ Long programs: {len([e for e in self.examples if e in self.generate_long_programs()])} examples")

        stateful = self.generate_stateful_operations()
        self.examples.extend(stateful)
        print(f"  âœ“ Stateful operations: {len(stateful)} examples")

        conditional = self.generate_conditional_logic()
        self.examples.extend(conditional)
        print(f"  âœ“ Conditional logic: {len(conditional)} examples")

        iteration = self.generate_iteration_patterns()
        self.examples.extend(iteration)
        print(f"  âœ“ Iteration patterns: {len(iteration)} examples")

        context = self.generate_context_maintenance()
        self.examples.extend(context)
        print(f"  âœ“ Context maintenance: {len(context)} examples")

        print(f"\nTotal Phase 3 examples: {len(self.examples)}")
        return self.examples

    def write_corpus(self, filename: str):
        """Write corpus to markdown file."""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# HLXL Brain - Phase 3: Long-form Reasoning Corpus\n\n")
            f.write("## Training Examples for Extended Sequences and Context Maintenance\n\n")
            f.write(f"Total examples: {len(self.examples)}\n\n")
            f.write("---\n\n")

            for i, (english, lcr) in enumerate(self.examples, 1):
                f.write(f"### Example {i}\n\n")
                f.write(f"**English:**\n{english}\n\n")
                f.write(f"**LC-R:**\n```\n{lcr}\n```\n\n")
                f.write("---\n\n")

        print(f"âœ“ Corpus written to {filename}")


if __name__ == "__main__":
    generator = Phase3CorpusGenerator()
    examples = generator.generate_all()
    generator.write_corpus("corpus_phase3_longform_reasoning.md")
    print("\nPhase 3 corpus generation complete!")
    print(f"Generated {len(examples)} examples")
    print("\nNext steps:")
    print("1. Review corpus_phase3_longform_reasoning.md")
    print("2. Merge with previous phases: cat corpus_combined_phase2.md corpus_phase3_longform_reasoning.md > corpus_combined_phase3.md")
    print("3. Update training script for Phase 3 (increase seq_length to 256)")
    print("4. Run: python3 train_phase3.py")
