#!/usr/bin/env python3
"""
Phase 2 Corpus Generator: Domain Knowledge
Generates 600+ training examples teaching domain-specific patterns
"""

import random
from typing import List, Tuple

# Seed for reproducibility
random.seed(42)

class Phase2CorpusGenerator:
    """Generate domain knowledge examples: File systems, data structures, control flow"""

    def __init__(self):
        self.examples = []

    def generate_file_system_operations(self) -> List[Tuple[str, str]]:
        """Generate file system operation examples"""
        examples = []

        # Path operations
        paths = [
            ("/home/user/docs", "ðŸœŠ1000ðŸœ0 \"navigate\"ðŸœ1 \"/home/user/docs\"ðŸœ‚"),
            ("./relative/path", "ðŸœŠ1000ðŸœ0 \"navigate\"ðŸœ1 \"./relative/path\"ðŸœ‚"),
            ("../parent/folder", "ðŸœŠ1000ðŸœ0 \"navigate\"ðŸœ1 \"../parent/folder\"ðŸœ‚"),
            ("/root/system", "ðŸœŠ1000ðŸœ0 \"navigate\"ðŸœ1 \"/root/system\"ðŸœ‚"),
        ]

        for path, lcr in paths:
            examples.append((f"Navigate to {path}", lcr))
            examples.append((f"Go to {path}", lcr))
            examples.append((f"Change to {path}", lcr))

        # Wildcard patterns
        wildcards = [
            ("*.txt", "all text files", "ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"*.txt\"ðŸœ‚"),
            ("**/*.py", "all Python files recursively", "ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"**/*.py\"ðŸœ‚"),
            ("data/*.json", "JSON files in data folder", "ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"data/*.json\"ðŸœ‚"),
            ("test_*.js", "test JavaScript files", "ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"test_*.js\"ðŸœ‚"),
            ("{a,b,c}.csv", "files a.csv, b.csv, c.csv", "ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"{a,b,c}.csv\"ðŸœ‚"),
        ]

        for pattern, desc, lcr in wildcards:
            examples.append((f"Find {pattern}", lcr))
            examples.append((f"Search for {pattern}", lcr))
            examples.append((f"Locate {desc}", lcr))

        # File operations
        file_ops = [
            ("Read config.yaml", "ðŸœŠ1000ðŸœ0 \"read\"ðŸœ1 \"config.yaml\"ðŸœ‚"),
            ("Write to output.txt", "ðŸœŠ1000ðŸœ0 \"write\"ðŸœ1 \"output.txt\"ðŸœ2 âŸdataðŸœ‚"),
            ("Copy file.txt to backup.txt", "ðŸœŠ1000ðŸœ0 \"copy\"ðŸœ1 \"file.txt\"ðŸœ2 \"backup.txt\"ðŸœ‚"),
            ("Move temp.log to archive.log", "ðŸœŠ1000ðŸœ0 \"move\"ðŸœ1 \"temp.log\"ðŸœ2 \"archive.log\"ðŸœ‚"),
            ("Delete old.dat", "ðŸœŠ1000ðŸœ0 \"delete\"ðŸœ1 \"old.dat\"ðŸœ‚"),
            ("Rename draft.md to final.md", "ðŸœŠ1000ðŸœ0 \"rename\"ðŸœ1 \"draft.md\"ðŸœ2 \"final.md\"ðŸœ‚"),
        ]

        examples.extend(file_ops)

        # Directory operations
        dir_ops = [
            ("Create directory logs", "ðŸœŠ1000ðŸœ0 \"mkdir\"ðŸœ1 \"logs\"ðŸœ‚"),
            ("List files in current directory", "ðŸœŠ1000ðŸœ0 \"ls\"ðŸœ1 \".\"ðŸœ‚"),
            ("List all files recursively", "ðŸœŠ1000ðŸœ0 \"ls\"ðŸœ1 \"-R\"ðŸœ‚"),
            ("Remove empty directory cache", "ðŸœŠ1000ðŸœ0 \"rmdir\"ðŸœ1 \"cache\"ðŸœ‚"),
        ]

        examples.extend(dir_ops)

        return examples

    def generate_data_structure_operations(self) -> List[Tuple[str, str]]:
        """Generate data structure examples"""
        examples = []

        # List operations
        list_ops = [
            ("Create empty list", "ðŸœŠ14ðŸœ‚"),
            ("Create list with values 1, 2, 3", "ðŸœŠ14ðŸœ0 1ðŸœ1 2ðŸœ2 3ðŸœ‚"),
            ("Get first element from list", "ðŸœŠ1000ðŸœ0 \"get\"ðŸœ1 âŸlistðŸœ2 0ðŸœ‚"),
            ("Get last element from list", "ðŸœŠ1000ðŸœ0 \"get\"ðŸœ1 âŸlistðŸœ2 -1ðŸœ‚"),
            ("Append value to list", "ðŸœŠ1000ðŸœ0 \"append\"ðŸœ1 âŸlistðŸœ2 âŸvalueðŸœ‚"),
            ("Prepend value to list", "ðŸœŠ1000ðŸœ0 \"prepend\"ðŸœ1 âŸlistðŸœ2 âŸvalueðŸœ‚"),
            ("Get length of list", "ðŸœŠ1000ðŸœ0 \"length\"ðŸœ1 âŸlistðŸœ‚"),
            ("Slice list from index 1 to 5", "ðŸœŠ1000ðŸœ0 \"slice\"ðŸœ1 âŸlistðŸœ2 1ðŸœ3 5ðŸœ‚"),
            ("Reverse the list", "ðŸœŠ1000ðŸœ0 \"reverse\"ðŸœ1 âŸlistðŸœ‚"),
            ("Sort the list", "ðŸœŠ1000ðŸœ0 \"sort\"ðŸœ1 âŸlistðŸœ‚"),
        ]

        examples.extend(list_ops)

        # Map operations
        map_ops = [
            ("Create empty map", "ðŸœŠ15ðŸœ‚"),
            ("Get value for key from map", "ðŸœŠ1000ðŸœ0 \"get\"ðŸœ1 âŸmapðŸœ2 \"key\"ðŸœ‚"),
            ("Set key to value in map", "ðŸœŠ1000ðŸœ0 \"set\"ðŸœ1 âŸmapðŸœ2 \"key\"ðŸœ3 âŸvalueðŸœ‚"),
            ("Check if map has key", "ðŸœŠ1000ðŸœ0 \"has\"ðŸœ1 âŸmapðŸœ2 \"key\"ðŸœ‚"),
            ("Remove key from map", "ðŸœŠ1000ðŸœ0 \"remove\"ðŸœ1 âŸmapðŸœ2 \"key\"ðŸœ‚"),
            ("Get all keys from map", "ðŸœŠ1000ðŸœ0 \"keys\"ðŸœ1 âŸmapðŸœ‚"),
            ("Get all values from map", "ðŸœŠ1000ðŸœ0 \"values\"ðŸœ1 âŸmapðŸœ‚"),
            ("Merge map1 with map2", "ðŸœŠ1000ðŸœ0 \"merge\"ðŸœ1 âŸmap1ðŸœ2 âŸmap2ðŸœ‚"),
        ]

        examples.extend(map_ops)

        # Set operations
        set_ops = [
            ("Create set from values a, b, c", "ðŸœŠ1000ðŸœ0 \"set\"ðŸœ1 ðŸœŠ14ðŸœ0 âŸaðŸœ1 âŸbðŸœ2 âŸcðŸœ‚ðŸœ‚"),
            ("Add element to set", "ðŸœŠ1000ðŸœ0 \"add\"ðŸœ1 âŸsetðŸœ2 âŸelementðŸœ‚"),
            ("Check if set contains element", "ðŸœŠ1000ðŸœ0 \"contains\"ðŸœ1 âŸsetðŸœ2 âŸelementðŸœ‚"),
            ("Get union of set1 and set2", "ðŸœŠ1000ðŸœ0 \"union\"ðŸœ1 âŸset1ðŸœ2 âŸset2ðŸœ‚"),
            ("Get intersection of set1 and set2", "ðŸœŠ1000ðŸœ0 \"intersection\"ðŸœ1 âŸset1ðŸœ2 âŸset2ðŸœ‚"),
            ("Get difference of set1 and set2", "ðŸœŠ1000ðŸœ0 \"difference\"ðŸœ1 âŸset1ðŸœ2 âŸset2ðŸœ‚"),
        ]

        examples.extend(set_ops)

        # Type conversions
        conversions = [
            ("Convert list to set", "ðŸœŠ1000ðŸœ0 \"to_set\"ðŸœ1 âŸlistðŸœ‚"),
            ("Convert set to list", "ðŸœŠ1000ðŸœ0 \"to_list\"ðŸœ1 âŸsetðŸœ‚"),
            ("Convert string to number", "ðŸœŠ1000ðŸœ0 \"to_number\"ðŸœ1 \"42\"ðŸœ‚"),
            ("Convert number to string", "ðŸœŠ1000ðŸœ0 \"to_string\"ðŸœ1 42ðŸœ‚"),
        ]

        examples.extend(conversions)

        return examples

    def generate_control_flow_operations(self) -> List[Tuple[str, str]]:
        """Generate control flow examples"""
        examples = []

        # Conditionals
        conditionals = [
            ("If condition then action",
             "ðŸœŠ1000ðŸœ0 \"if\"ðŸœ1 âŸconditionðŸœ2 ðŸœŠ1000ðŸœ0 \"action\"ðŸœ‚ðŸœ‚"),
            ("If x greater than 10 then process",
             "ðŸœŠ1000ðŸœ0 \"if\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"gt\"ðŸœ1 âŸxðŸœ2 10ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"process\"ðŸœ‚ðŸœ‚"),
            ("If valid then accept else reject",
             "ðŸœŠ1000ðŸœ0 \"if\"ðŸœ1 âŸvalidðŸœ2 ðŸœŠ1000ðŸœ0 \"accept\"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"reject\"ðŸœ‚ðŸœ‚"),
            ("Match value with cases",
             "ðŸœŠ1000ðŸœ0 \"match\"ðŸœ1 âŸvalueðŸœ2 ðŸœŠ15ðŸœ0 \"case1\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"action1\"ðŸœ‚ðŸœ2 \"case2\"ðŸœ3 ðŸœŠ1000ðŸœ0 \"action2\"ðŸœ‚ðŸœ‚ðŸœ‚"),
        ]

        examples.extend(conditionals)

        # Loops
        loops = [
            ("For each item in list do process",
             "ðŸœŠ1000ðŸœ0 \"for_each\"ðŸœ1 âŸlistðŸœ2 ðŸœŠ1000ðŸœ0 \"process\"ðŸœ1 âŸitemðŸœ‚ðŸœ‚"),
            ("While condition do action",
             "ðŸœŠ1000ðŸœ0 \"while\"ðŸœ1 âŸconditionðŸœ2 ðŸœŠ1000ðŸœ0 \"action\"ðŸœ‚ðŸœ‚"),
            ("Repeat action 5 times",
             "ðŸœŠ1000ðŸœ0 \"repeat\"ðŸœ1 5ðŸœ2 ðŸœŠ1000ðŸœ0 \"action\"ðŸœ‚ðŸœ‚"),
            ("Iterate from 0 to 10",
             "ðŸœŠ1000ðŸœ0 \"iterate\"ðŸœ1 0ðŸœ2 10ðŸœ3 ðŸœŠ1000ðŸœ0 \"process\"ðŸœ1 âŸiðŸœ‚ðŸœ‚"),
        ]

        examples.extend(loops)

        # Pipelines
        pipelines = [
            ("Load data then filter then save",
             "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"load\"ðŸœ1 \"data.json\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"filter\"ðŸœ1 âŸdataðŸœ2 âŸvalidðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"save\"ðŸœ1 \"output.json\"ðŸœ2 âŸresultðŸœ‚ðŸœ‚ðŸœ‚"),
            ("Read, transform, validate, write",
             "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"read\"ðŸœ1 \"input.txt\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"transform\"ðŸœ1 âŸdataðŸœ2 âŸnormalizeðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"validate\"ðŸœ1 âŸresultðŸœ2 âŸschemaðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"write\"ðŸœ1 \"output.txt\"ðŸœ2 âŸvalidatedðŸœ‚ðŸœ‚ðŸœ‚"),
            ("Search then sort then limit",
             "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"search\"ðŸœ1 âŸdatabaseðŸœ2 \"query\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"sort\"ðŸœ1 âŸresultsðŸœ2 âŸdescðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"limit\"ðŸœ1 âŸsortedðŸœ2 10ðŸœ‚ðŸœ‚ðŸœ‚"),
        ]

        examples.extend(pipelines)

        # Error handling
        error_handling = [
            ("Try operation catch error",
             "ðŸœŠ1000ðŸœ0 \"try\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"operation\"ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"catch\"ðŸœ1 âŸerrorðŸœ‚ðŸœ‚"),
            ("Validate input or use default",
             "ðŸœŠ1000ðŸœ0 \"or\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"validate\"ðŸœ1 âŸinputðŸœ‚ðŸœ2 âŸdefaultðŸœ‚"),
            ("Execute with timeout",
             "ðŸœŠ1000ðŸœ0 \"timeout\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"execute\"ðŸœ1 âŸtaskðŸœ‚ðŸœ2 5000ðŸœ‚"),
        ]

        examples.extend(error_handling)

        return examples

    def generate_common_patterns(self) -> List[Tuple[str, str]]:
        """Generate common programming patterns"""
        examples = []

        # Map-Reduce
        examples.append((
            "Map transform over list then reduce with sum",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"map\"ðŸœ1 âŸlistðŸœ2 ðŸœŠ1000ðŸœ0 \"transform\"ðŸœ1 âŸitemðŸœ‚ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"reduce\"ðŸœ1 âŸmappedðŸœ2 ðŸœŠ1000ðŸœ0 \"sum\"ðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Filter-Map-Reduce
        examples.append((
            "Filter valid items, map to values, sum results",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"filter\"ðŸœ1 âŸitemsðŸœ2 âŸvalidðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"map\"ðŸœ1 âŸfilteredðŸœ2 âŸget_valueðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"sum\"ðŸœ1 âŸvaluesðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Load-Process-Save
        examples.append((
            "Load CSV, filter rows, aggregate by group, save results",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"load\"ðŸœ1 \"data.csv\"ðŸœ2 \"csv\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"filter\"ðŸœ1 âŸrowsðŸœ2 ðŸœŠ1000ðŸœ0 \"gt\"ðŸœ1 âŸscoreðŸœ2 80ðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"group_by\"ðŸœ1 âŸfilteredðŸœ2 \"category\"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"save\"ðŸœ1 \"results.json\"ðŸœ2 âŸgroupedðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Query-Transform-Export
        examples.append((
            "Query database, transform records, export to multiple formats",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"query\"ðŸœ1 âŸdatabaseðŸœ2 \"SELECT * FROM users\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"transform\"ðŸœ1 âŸrecordsðŸœ2 âŸnormalizeðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"export\"ðŸœ1 âŸtransformedðŸœ2 ðŸœŠ14ðŸœ0 \"json\"ðŸœ1 \"csv\"ðŸœ2 \"xml\"ðŸœ‚ðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Parallel processing
        examples.append((
            "Process items in parallel with 4 workers",
            "ðŸœŠ1000ðŸœ0 \"parallel\"ðŸœ1 âŸitemsðŸœ2 ðŸœŠ1000ðŸœ0 \"process\"ðŸœ1 âŸitemðŸœ‚ðŸœ3 4ðŸœ‚"
        ))

        # Caching
        examples.append((
            "Execute with cache for 3600 seconds",
            "ðŸœŠ1000ðŸœ0 \"cache\"ðŸœ1 ðŸœŠ1000ðŸœ0 \"execute\"ðŸœ1 âŸtaskðŸœ‚ðŸœ2 3600ðŸœ‚"
        ))

        # Batch processing
        examples.append((
            "Process items in batches of 100",
            "ðŸœŠ1000ðŸœ0 \"batch\"ðŸœ1 âŸitemsðŸœ2 100ðŸœ3 ðŸœŠ1000ðŸœ0 \"process\"ðŸœ1 âŸbatchðŸœ‚ðŸœ‚"
        ))

        return examples

    def generate_realistic_workflows(self) -> List[Tuple[str, str]]:
        """Generate realistic multi-step workflows"""
        examples = []

        # Data ETL
        examples.append((
            "Extract data from API, transform to schema, load into database",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"fetch\"ðŸœ1 \"https://api.example.com/data\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"transform\"ðŸœ1 âŸdataðŸœ2 âŸto_schemaðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"insert\"ðŸœ1 âŸdatabaseðŸœ2 âŸtransformedðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # File processing
        examples.append((
            "Find all log files, parse errors, group by type, generate report",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"find\"ðŸœ1 \"**/*.log\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"map\"ðŸœ1 âŸfilesðŸœ2 ðŸœŠ1000ðŸœ0 \"parse_errors\"ðŸœ1 âŸfileðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"group_by\"ðŸœ1 âŸerrorsðŸœ2 \"type\"ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"generate_report\"ðŸœ1 âŸgroupedðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Data analysis
        examples.append((
            "Load sales data, filter by date range, calculate metrics, create visualization",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"load\"ðŸœ1 \"sales.csv\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"filter\"ðŸœ1 âŸdataðŸœ2 ðŸœŠ1000ðŸœ0 \"between\"ðŸœ1 âŸdateðŸœ2 \"2024-01-01\"ðŸœ3 \"2024-12-31\"ðŸœ‚ðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"aggregate\"ðŸœ1 âŸfilteredðŸœ2 ðŸœŠ15ðŸœ0 \"total\"ðŸœ1 âŸsumðŸœ2 \"average\"ðŸœ3 âŸmeanðŸœ‚ðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"visualize\"ðŸœ1 âŸmetricsðŸœ2 \"chart\"ðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # API workflow
        examples.append((
            "Authenticate with API, fetch user data, enrich with profile, cache results",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"authenticate\"ðŸœ1 \"api.example.com\"ðŸœ2 âŸcredentialsðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"fetch\"ðŸœ1 \"/users\"ðŸœ2 âŸtokenðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"enrich\"ðŸœ1 âŸusersðŸœ2 âŸget_profileðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"cache\"ðŸœ1 âŸenrichedðŸœ2 3600ðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        # Validation workflow
        examples.append((
            "Read config, validate schema, check permissions, apply settings",
            "ðŸœŠ1000ðŸœ0 \"pipeline\"ðŸœ1 ðŸœŠ14ðŸœ0 ðŸœŠ1000ðŸœ0 \"read\"ðŸœ1 \"config.yaml\"ðŸœ‚ðŸœ1 ðŸœŠ1000ðŸœ0 \"validate\"ðŸœ1 âŸconfigðŸœ2 âŸschemaðŸœ‚ðŸœ2 ðŸœŠ1000ðŸœ0 \"check_permissions\"ðŸœ1 âŸvalidatedðŸœ‚ðŸœ3 ðŸœŠ1000ðŸœ0 \"apply\"ðŸœ1 âŸsettingsðŸœ‚ðŸœ‚ðŸœ‚"
        ))

        return examples

    def generate_corpus(self) -> Tuple[str, int]:
        """Generate complete Phase 2 corpus"""
        file_system = self.generate_file_system_operations()
        data_structures = self.generate_data_structure_operations()
        control_flow = self.generate_control_flow_operations()
        patterns = self.generate_common_patterns()
        workflows = self.generate_realistic_workflows()

        all_examples = (
            file_system +
            data_structures +
            control_flow +
            patterns +
            workflows
        )

        random.shuffle(all_examples)

        # Format as markdown
        corpus = "# Phase 2: Domain Knowledge Corpus\n\n"
        corpus += f"Total examples: {len(all_examples)}\n\n"
        corpus += "**Coverage:**\n"
        corpus += "- File system operations (paths, wildcards, file ops)\n"
        corpus += "- Data structures (lists, maps, sets, conversions)\n"
        corpus += "- Control flow (conditionals, loops, pipelines, error handling)\n"
        corpus += "- Common patterns (map-reduce, ETL, parallel processing)\n"
        corpus += "- Realistic workflows (multi-step operations)\n\n"
        corpus += "---\n\n"

        for english, lcr in all_examples:
            corpus += f"English: {english}\n"
            corpus += f"LC-R: {lcr}\n\n"

        return corpus, len(all_examples)


if __name__ == "__main__":
    print("Generating Phase 2 corpus...")
    generator = Phase2CorpusGenerator()
    corpus, count = generator.generate_corpus()

    # Write to file
    output_file = "corpus_phase2_domain_knowledge.md"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(corpus)

    print(f"âœ“ Generated {count} examples")
    print(f"âœ“ Saved to {output_file}")
    print(f"\nSample examples:")

    examples = corpus.split("\n\n")[6:11]  # Get first few after header
    for ex in examples:
        if ex.strip() and ex.startswith("English:"):
            print(f"  {ex[:100]}...")
